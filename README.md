# ğŸ§  DeepSeek Agent

A local AI assistant powered by [LangChain](https://github.com/langchain-ai/langchain), [LangGraph](https://github.com/langchain-ai/langgraph), and [Ollama](https://github.com/ollama/ollama), using the `deepseek-coder-v2` model.

Supports:
- ğŸ–¥ Terminal interface
- ğŸŒ Web UI with Gradio
- ğŸ§© Plug-and-play LangChain agents

---

## ğŸ“¦ Installation

1. **Clone the repo:**

```bash
git clone https://github.com/ekalachev/agent_ai.git
cd agent_ai
```

2.	(Optional but recommended) Create a virtual environment:
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3.	Install dependencies:

```bash
pip install -r requirements.txt
```


â¸»

ğŸ¤– Run in Terminal

```bash
./run_agentic_cli.sh
```

Youâ€™ll see:

ğŸ”¹ DeepSeek Agent (terminal mode). Type Ctrl-C or 'exit' to quit.



â¸»

ğŸŒ Run the Web UI

```bash
./run_agentic_app.sh
```

The UI will launch in your browser. You can also share the link with others.

â¸»

ğŸ§  Model Used

This project uses the `deepseek-coder-v2:16b-lite-instruct-q4_K_M` model via Ollama.

Make sure itâ€™s installed locally:
```bash
ollama pull deepseek-coder-v2:16b-lite-instruct-q4_K_M
```

â¸»

ğŸ” Optional: Use Tavily Search Tool

If you want to enable search with Tavily, set your API key:

```python
export TAVILY_API_KEY=your_api_key_here
```

And uncomment this line in src/agent.py:

```python
# search = TavilySearchResults(max_results=2)
# tools = [search]
```
